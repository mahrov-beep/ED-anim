//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31968024
// Cuda compilation tools, release 12.0, V12.0.76
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	__raygen__oxMain
.const .align 16 .b8 params[1184];

.visible .entry __raygen__oxMain()
{
	.reg .pred 	%p<65>;
	.reg .b16 	%rs<17>;
	.reg .f32 	%f<1295>;
	.reg .b32 	%r<2015>;
	.reg .b64 	%rd<46>;


	// begin inline asm
	call (%r7), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r8), _optix_get_launch_index_y, ();
	// end inline asm
	ld.const.u64 	%rd3, [params+400];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.const.u32 	%r13, [params+392];
	mad.lo.s32 	%r14, %r13, %r8, %r7;
	mul.wide.u32 	%rd5, %r14, 4;
	add.s64 	%rd1, %rd4, %rd5;
	ld.global.v2.u8 	{%rs7, %rs16}, [%rd1];
	or.b16  	%rs9, %rs7, %rs16;
	and.b16  	%rs10, %rs9, 255;
	setp.eq.s16 	%p1, %rs10, 0;
	@%p1 bra 	$L__BB0_2;

	ld.global.u8 	%rs15, [%rd1+2];
	bra.uni 	$L__BB0_3;

$L__BB0_2:
	ld.global.u8 	%rs15, [%rd1+2];
	setp.eq.s16 	%p2, %rs15, 0;
	mov.f32 	%f1179, 0f00000000;
	mov.u16 	%rs16, 0;
	mov.f32 	%f1180, %f1179;
	mov.f32 	%f1181, %f1179;
	@%p2 bra 	$L__BB0_4;

$L__BB0_3:
	cvt.rn.f32.u16 	%f386, %rs7;
	div.rn.f32 	%f387, %f386, 0f437F0000;
	fma.rn.f32 	%f388, %f387, 0f40000000, 0fBF800000;
	and.b16  	%rs13, %rs16, 255;
	cvt.rn.f32.u16 	%f389, %rs13;
	div.rn.f32 	%f390, %f389, 0f437F0000;
	fma.rn.f32 	%f391, %f390, 0f40000000, 0fBF800000;
	cvt.rn.f32.u16 	%f392, %rs15;
	div.rn.f32 	%f393, %f392, 0f437F0000;
	fma.rn.f32 	%f394, %f393, 0f40000000, 0fBF800000;
	mul.f32 	%f395, %f391, %f391;
	fma.rn.f32 	%f396, %f388, %f388, %f395;
	fma.rn.f32 	%f397, %f394, %f394, %f396;
	sqrt.rn.f32 	%f398, %f397;
	rcp.rn.f32 	%f399, %f398;
	mul.f32 	%f1181, %f399, %f394;
	mul.f32 	%f1180, %f399, %f391;
	mul.f32 	%f1179, %f388, %f399;

$L__BB0_4:
	ld.const.v2.u32 	{%r15, %r16}, [params];
	add.s32 	%r3, %r15, %r7;
	add.s32 	%r4, %r16, %r8;
	setp.eq.f32 	%p3, %f1179, 0f00000000;
	setp.eq.f32 	%p4, %f1180, 0f00000000;
	and.pred  	%p5, %p3, %p4;
	setp.eq.f32 	%p6, %f1181, 0f00000000;
	and.pred  	%p7, %p6, %p5;
	@%p7 bra 	$L__BB0_64;
	bra.uni 	$L__BB0_5;

$L__BB0_64:
	ld.const.u64 	%rd42, [params+224];
	cvta.to.global.u64 	%rd43, %rd42;
	ld.const.u32 	%r2012, [params+216];
	mad.lo.s32 	%r2013, %r2012, %r4, %r3;
	mul.wide.u32 	%rd44, %r2013, 16;
	add.s64 	%rd45, %rd43, %rd44;
	mov.f32 	%f1140, 0f00000000;
	st.global.v4.f32 	[%rd45], {%f1140, %f1140, %f1140, %f1140};
	bra.uni 	$L__BB0_65;

$L__BB0_5:
	ld.const.u64 	%rd7, [params+432];
	cvta.to.global.u64 	%rd8, %rd7;
	ld.const.u32 	%r90, [params+424];
	mad.lo.s32 	%r91, %r90, %r8, %r7;
	mul.wide.u32 	%rd9, %r91, 12;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.f32 	%f7, [%rd10];
	mul.f32 	%f410, %f7, 0f3456BF95;
	ld.global.f32 	%f8, [%rd10+4];
	mul.f32 	%f411, %f8, 0f3456BF95;
	ld.global.f32 	%f9, [%rd10+8];
	mul.f32 	%f412, %f9, 0f3456BF95;
	abs.f32 	%f413, %f410;
	abs.f32 	%f414, %f411;
	abs.f32 	%f415, %f412;
	max.f32 	%f416, %f413, %f414;
	max.f32 	%f417, %f416, %f415;
	mov.f32 	%f418, 0f38D1B717;
	max.f32 	%f10, %f417, %f418;
	ld.const.v2.f32 	{%f419, %f420}, [params+728];
	mov.u32 	%r89, 0;
	mov.u32 	%r52, 1;
	ld.const.u64 	%rd2, [params+96];
	add.f32 	%f16, %f10, %f10;
	mul.f32 	%f17, %f419, 0f00000000;
	mov.f32 	%f408, 0f00000000;
	ld.const.f32 	%f18, [params+724];
	sub.f32 	%f421, %f17, %f18;
	mul.f32 	%f19, %f420, 0f00000000;
	add.f32 	%f422, %f421, %f19;
	abs.f32 	%f407, %f422;
	mov.f32 	%f403, 0fBF800000;
	mov.u32 	%r55, 2;
	mov.u32 	%r57, 3;
	// begin inline asm
	call(%r19,%r20,%r21,%r22,%r23,%r24,%r25,%r26,%r27,%r28,%r29,%r30,%r31,%r32,%r33,%r34,%r35,%r36,%r37,%r38,%r39,%r40,%r41,%r42,%r43,%r44,%r45,%r46,%r47,%r48,%r49,%r50),_optix_trace_typed_32,(%r89,%rd2,%f7,%f8,%f9,%f403,%f408,%f408,%f408,%f407,%f408,%r52,%r89,%r89,%r55,%r89,%r57,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89);
	// end inline asm
	mov.b32 	%f21, %r19;
	mov.b32 	%f22, %r20;
	mov.b32 	%f23, %r21;
	abs.f32 	%f423, %f21;
	abs.f32 	%f424, %f22;
	add.f32 	%f425, %f423, %f424;
	abs.f32 	%f426, %f23;
	add.f32 	%f427, %f425, %f426;
	setp.eq.f32 	%p8, %f427, 0f00000000;
	mov.f32 	%f1189, 0f47C34F80;
	mov.f32 	%f1186, %f7;
	mov.f32 	%f1187, %f8;
	mov.f32 	%f1188, %f9;
	@%p8 bra 	$L__BB0_7;

	mul.f32 	%f428, %f22, %f22;
	fma.rn.f32 	%f429, %f21, %f21, %f428;
	fma.rn.f32 	%f430, %f23, %f23, %f429;
	sqrt.rn.f32 	%f431, %f430;
	max.f32 	%f432, %f431, %f10;
	rcp.rn.f32 	%f433, %f431;
	mul.f32 	%f434, %f433, %f21;
	mul.f32 	%f435, %f433, %f22;
	mul.f32 	%f436, %f433, %f23;
	fma.rn.f32 	%f437, %f10, %f434, %f7;
	fma.rn.f32 	%f438, %f10, %f435, %f8;
	fma.rn.f32 	%f439, %f10, %f436, %f9;
	add.f32 	%f440, %f16, %f432;
	setp.lt.f32 	%p9, %f432, 0f47C34F80;
	sub.f32 	%f441, %f437, %f440;
	fma.rn.f32 	%f442, %f440, 0f00000000, %f438;
	fma.rn.f32 	%f443, %f440, 0f00000000, %f439;
	selp.f32 	%f1188, %f443, %f9, %p9;
	selp.f32 	%f1187, %f442, %f8, %p9;
	selp.f32 	%f1186, %f441, %f7, %p9;
	min.f32 	%f1189, %f432, 0f47C34F80;

$L__BB0_7:
	mul.f32 	%f1157, %f420, 0f00000000;
	mul.f32 	%f1156, %f419, 0f00000000;
	ld.const.f32 	%f1155, [params+724];
	add.f32 	%f453, %f1155, %f1156;
	add.f32 	%f454, %f453, %f1157;
	abs.f32 	%f451, %f454;
	mov.f32 	%f447, 0f3F800000;
	// begin inline asm
	call(%r92,%r93,%r94,%r95,%r96,%r97,%r98,%r99,%r100,%r101,%r102,%r103,%r104,%r105,%r106,%r107,%r108,%r109,%r110,%r111,%r112,%r113,%r114,%r115,%r116,%r117,%r118,%r119,%r120,%r121,%r122,%r123),_optix_trace_typed_32,(%r89,%rd2,%f7,%f8,%f9,%f447,%f408,%f408,%f408,%f451,%f408,%r52,%r89,%r89,%r55,%r89,%r57,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89,%r89);
	// end inline asm
	mov.b32 	%f33, %r92;
	mov.b32 	%f34, %r93;
	mov.b32 	%f35, %r94;
	abs.f32 	%f455, %f33;
	abs.f32 	%f456, %f34;
	add.f32 	%f457, %f455, %f456;
	abs.f32 	%f458, %f35;
	add.f32 	%f459, %f457, %f458;
	setp.eq.f32 	%p10, %f459, 0f00000000;
	@%p10 bra 	$L__BB0_9;

	mul.f32 	%f460, %f34, %f34;
	fma.rn.f32 	%f461, %f33, %f33, %f460;
	fma.rn.f32 	%f462, %f35, %f35, %f461;
	sqrt.rn.f32 	%f463, %f462;
	max.f32 	%f464, %f463, %f10;
	rcp.rn.f32 	%f465, %f463;
	mul.f32 	%f466, %f465, %f33;
	mul.f32 	%f467, %f465, %f34;
	mul.f32 	%f468, %f465, %f35;
	fma.rn.f32 	%f469, %f10, %f466, %f7;
	fma.rn.f32 	%f470, %f10, %f467, %f8;
	fma.rn.f32 	%f471, %f10, %f468, %f9;
	add.f32 	%f472, %f16, %f464;
	setp.lt.f32 	%p11, %f464, %f1189;
	add.f32 	%f473, %f472, %f469;
	fma.rn.f32 	%f474, %f472, 0f00000000, %f470;
	fma.rn.f32 	%f475, %f472, 0f00000000, %f471;
	selp.f32 	%f1188, %f475, %f1188, %p11;
	selp.f32 	%f1187, %f474, %f1187, %p11;
	selp.f32 	%f1186, %f473, %f1186, %p11;
	selp.f32 	%f1189, %f464, %f1189, %p11;

$L__BB0_9:
	mul.f32 	%f1159, %f420, 0f00000000;
	ld.const.f32 	%f1158, [params+724];
	mul.f32 	%f44, %f1158, 0f00000000;
	mov.f32 	%f484, 0f00000000;
	sub.f32 	%f485, %f44, %f419;
	add.f32 	%f486, %f485, %f1159;
	abs.f32 	%f483, %f486;
	mov.f32 	%f480, 0fBF800000;
	mov.u32 	%r196, 1;
	mov.u32 	%r199, 2;
	mov.u32 	%r201, 3;
	mov.u32 	%r233, 0;
	// begin inline asm
	call(%r163,%r164,%r165,%r166,%r167,%r168,%r169,%r170,%r171,%r172,%r173,%r174,%r175,%r176,%r177,%r178,%r179,%r180,%r181,%r182,%r183,%r184,%r185,%r186,%r187,%r188,%r189,%r190,%r191,%r192,%r193,%r194),_optix_trace_typed_32,(%r233,%rd2,%f7,%f8,%f9,%f484,%f480,%f484,%f484,%f483,%f484,%r196,%r233,%r233,%r199,%r233,%r201,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233);
	// end inline asm
	mov.b32 	%f46, %r163;
	mov.b32 	%f47, %r164;
	mov.b32 	%f48, %r165;
	abs.f32 	%f487, %f46;
	abs.f32 	%f488, %f47;
	add.f32 	%f489, %f487, %f488;
	abs.f32 	%f490, %f48;
	add.f32 	%f491, %f489, %f490;
	setp.eq.f32 	%p12, %f491, 0f00000000;
	@%p12 bra 	$L__BB0_11;

	mul.f32 	%f492, %f47, %f47;
	fma.rn.f32 	%f493, %f46, %f46, %f492;
	fma.rn.f32 	%f494, %f48, %f48, %f493;
	sqrt.rn.f32 	%f495, %f494;
	max.f32 	%f496, %f495, %f10;
	rcp.rn.f32 	%f497, %f495;
	mul.f32 	%f498, %f497, %f46;
	mul.f32 	%f499, %f497, %f47;
	mul.f32 	%f500, %f497, %f48;
	fma.rn.f32 	%f501, %f10, %f498, %f7;
	fma.rn.f32 	%f502, %f10, %f499, %f8;
	fma.rn.f32 	%f503, %f10, %f500, %f9;
	add.f32 	%f504, %f16, %f496;
	setp.lt.f32 	%p13, %f496, %f1189;
	fma.rn.f32 	%f505, %f504, 0f00000000, %f501;
	sub.f32 	%f506, %f502, %f504;
	fma.rn.f32 	%f507, %f504, 0f00000000, %f503;
	selp.f32 	%f1188, %f507, %f1188, %p13;
	selp.f32 	%f1187, %f506, %f1187, %p13;
	selp.f32 	%f1186, %f505, %f1186, %p13;
	selp.f32 	%f1189, %f496, %f1189, %p13;

$L__BB0_11:
	ld.const.f32 	%f1164, [params+724];
	mul.f32 	%f1163, %f1164, 0f00000000;
	mul.f32 	%f1160, %f420, 0f00000000;
	add.f32 	%f517, %f1163, %f419;
	add.f32 	%f518, %f517, %f1160;
	abs.f32 	%f515, %f518;
	mov.f32 	%f512, 0f3F800000;
	// begin inline asm
	call(%r234,%r235,%r236,%r237,%r238,%r239,%r240,%r241,%r242,%r243,%r244,%r245,%r246,%r247,%r248,%r249,%r250,%r251,%r252,%r253,%r254,%r255,%r256,%r257,%r258,%r259,%r260,%r261,%r262,%r263,%r264,%r265),_optix_trace_typed_32,(%r233,%rd2,%f7,%f8,%f9,%f484,%f512,%f484,%f484,%f515,%f484,%r196,%r233,%r233,%r199,%r233,%r201,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233,%r233);
	// end inline asm
	mov.b32 	%f58, %r234;
	mov.b32 	%f59, %r235;
	mov.b32 	%f60, %r236;
	abs.f32 	%f519, %f58;
	abs.f32 	%f520, %f59;
	add.f32 	%f521, %f519, %f520;
	abs.f32 	%f522, %f60;
	add.f32 	%f523, %f521, %f522;
	setp.eq.f32 	%p14, %f523, 0f00000000;
	@%p14 bra 	$L__BB0_13;

	mul.f32 	%f524, %f59, %f59;
	fma.rn.f32 	%f525, %f58, %f58, %f524;
	fma.rn.f32 	%f526, %f60, %f60, %f525;
	sqrt.rn.f32 	%f527, %f526;
	max.f32 	%f528, %f527, %f10;
	rcp.rn.f32 	%f529, %f527;
	mul.f32 	%f530, %f529, %f58;
	mul.f32 	%f531, %f529, %f59;
	mul.f32 	%f532, %f529, %f60;
	fma.rn.f32 	%f533, %f10, %f530, %f7;
	fma.rn.f32 	%f534, %f10, %f531, %f8;
	fma.rn.f32 	%f535, %f10, %f532, %f9;
	add.f32 	%f536, %f16, %f528;
	setp.lt.f32 	%p15, %f528, %f1189;
	fma.rn.f32 	%f537, %f536, 0f00000000, %f533;
	add.f32 	%f538, %f534, %f536;
	fma.rn.f32 	%f539, %f536, 0f00000000, %f535;
	selp.f32 	%f1188, %f539, %f1188, %p15;
	selp.f32 	%f1187, %f538, %f1187, %p15;
	selp.f32 	%f1186, %f537, %f1186, %p15;
	selp.f32 	%f1189, %f528, %f1189, %p15;

$L__BB0_13:
	ld.const.f32 	%f1166, [params+724];
	mul.f32 	%f1165, %f1166, 0f00000000;
	mul.f32 	%f1161, %f419, 0f00000000;
	add.f32 	%f69, %f1165, %f1161;
	sub.f32 	%f549, %f69, %f420;
	abs.f32 	%f547, %f549;
	mov.f32 	%f545, 0fBF800000;
	mov.f32 	%f548, 0f00000000;
	mov.u32 	%r338, 1;
	mov.u32 	%r341, 2;
	mov.u32 	%r343, 3;
	mov.u32 	%r375, 0;
	// begin inline asm
	call(%r305,%r306,%r307,%r308,%r309,%r310,%r311,%r312,%r313,%r314,%r315,%r316,%r317,%r318,%r319,%r320,%r321,%r322,%r323,%r324,%r325,%r326,%r327,%r328,%r329,%r330,%r331,%r332,%r333,%r334,%r335,%r336),_optix_trace_typed_32,(%r375,%rd2,%f7,%f8,%f9,%f548,%f548,%f545,%f548,%f547,%f548,%r338,%r375,%r375,%r341,%r375,%r343,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375);
	// end inline asm
	mov.b32 	%f71, %r305;
	mov.b32 	%f72, %r306;
	mov.b32 	%f73, %r307;
	abs.f32 	%f550, %f71;
	abs.f32 	%f551, %f72;
	add.f32 	%f552, %f550, %f551;
	abs.f32 	%f553, %f73;
	add.f32 	%f554, %f552, %f553;
	setp.eq.f32 	%p16, %f554, 0f00000000;
	@%p16 bra 	$L__BB0_15;

	mul.f32 	%f555, %f72, %f72;
	fma.rn.f32 	%f556, %f71, %f71, %f555;
	fma.rn.f32 	%f557, %f73, %f73, %f556;
	sqrt.rn.f32 	%f558, %f557;
	max.f32 	%f559, %f558, %f10;
	rcp.rn.f32 	%f560, %f558;
	mul.f32 	%f561, %f560, %f71;
	mul.f32 	%f562, %f560, %f72;
	mul.f32 	%f563, %f560, %f73;
	fma.rn.f32 	%f564, %f10, %f561, %f7;
	fma.rn.f32 	%f565, %f10, %f562, %f8;
	fma.rn.f32 	%f566, %f10, %f563, %f9;
	add.f32 	%f567, %f16, %f559;
	setp.lt.f32 	%p17, %f559, %f1189;
	fma.rn.f32 	%f568, %f567, 0f00000000, %f564;
	fma.rn.f32 	%f569, %f567, 0f00000000, %f565;
	sub.f32 	%f570, %f566, %f567;
	selp.f32 	%f1188, %f570, %f1188, %p17;
	selp.f32 	%f1187, %f569, %f1187, %p17;
	selp.f32 	%f1186, %f568, %f1186, %p17;
	selp.f32 	%f1189, %f559, %f1189, %p17;

$L__BB0_15:
	add.f32 	%f580, %f69, %f420;
	abs.f32 	%f578, %f580;
	mov.f32 	%f576, 0f3F800000;
	// begin inline asm
	call(%r376,%r377,%r378,%r379,%r380,%r381,%r382,%r383,%r384,%r385,%r386,%r387,%r388,%r389,%r390,%r391,%r392,%r393,%r394,%r395,%r396,%r397,%r398,%r399,%r400,%r401,%r402,%r403,%r404,%r405,%r406,%r407),_optix_trace_typed_32,(%r375,%rd2,%f7,%f8,%f9,%f548,%f548,%f576,%f548,%f578,%f548,%r338,%r375,%r375,%r341,%r375,%r343,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375,%r375);
	// end inline asm
	mov.b32 	%f83, %r376;
	mov.b32 	%f84, %r377;
	mov.b32 	%f85, %r378;
	abs.f32 	%f581, %f83;
	abs.f32 	%f582, %f84;
	add.f32 	%f583, %f581, %f582;
	abs.f32 	%f584, %f85;
	add.f32 	%f585, %f583, %f584;
	setp.eq.f32 	%p18, %f585, 0f00000000;
	@%p18 bra 	$L__BB0_17;

	mul.f32 	%f586, %f84, %f84;
	fma.rn.f32 	%f587, %f83, %f83, %f586;
	fma.rn.f32 	%f588, %f85, %f85, %f587;
	sqrt.rn.f32 	%f589, %f588;
	max.f32 	%f590, %f589, %f10;
	rcp.rn.f32 	%f591, %f589;
	mul.f32 	%f592, %f591, %f83;
	mul.f32 	%f593, %f591, %f84;
	mul.f32 	%f594, %f591, %f85;
	fma.rn.f32 	%f595, %f10, %f592, %f7;
	fma.rn.f32 	%f596, %f10, %f593, %f8;
	fma.rn.f32 	%f597, %f10, %f594, %f9;
	add.f32 	%f598, %f16, %f590;
	setp.lt.f32 	%p19, %f590, %f1189;
	fma.rn.f32 	%f599, %f598, 0f00000000, %f595;
	fma.rn.f32 	%f600, %f598, 0f00000000, %f596;
	add.f32 	%f601, %f597, %f598;
	selp.f32 	%f1188, %f601, %f1188, %p19;
	selp.f32 	%f1187, %f600, %f1187, %p19;
	selp.f32 	%f1186, %f599, %f1186, %p19;

$L__BB0_17:
	ld.const.f32 	%f1162, [params+724];
	mul.f32 	%f98, %f10, 0f00000000;
	mul.f32 	%f602, %f419, 0fBF3504F3;
	fma.rn.f32 	%f603, %f1162, 0fBF3504F3, %f602;
	fma.rn.f32 	%f96, %f420, 0f00000000, %f603;
	mul.f32 	%f97, %f10, 0fBF3504F3;
	mul.f32 	%f604, %f419, 0f3F3504F3;
	fma.rn.f32 	%f605, %f1162, 0fBF3504F3, %f604;
	fma.rn.f32 	%f99, %f420, 0f00000000, %f605;
	mul.f32 	%f100, %f10, 0f3F3504F3;
	fma.rn.f32 	%f606, %f1162, 0f3F3504F3, %f604;
	fma.rn.f32 	%f101, %f420, 0f00000000, %f606;
	fma.rn.f32 	%f607, %f1162, 0f3F3504F3, %f602;
	fma.rn.f32 	%f102, %f420, 0f00000000, %f607;
	fma.rn.f32 	%f608, %f1162, 0f00000000, %f602;
	fma.rn.f32 	%f103, %f420, 0fBF3504F3, %f608;
	fma.rn.f32 	%f104, %f420, 0f3F3504F3, %f608;
	fma.rn.f32 	%f609, %f1162, 0f00000000, %f604;
	fma.rn.f32 	%f105, %f420, 0f3F3504F3, %f609;
	fma.rn.f32 	%f106, %f420, 0fBF3504F3, %f609;
	mul.f32 	%f610, %f419, 0fBF13CD3A;
	fma.rn.f32 	%f611, %f1162, 0fBF13CD3A, %f610;
	fma.rn.f32 	%f107, %f420, 0fBF13CD3A, %f611;
	mul.f32 	%f108, %f10, 0fBF13CD3A;
	fma.rn.f32 	%f109, %f420, 0f3F13CD3A, %f611;
	mul.f32 	%f110, %f10, 0f3F13CD3A;
	fma.rn.f32 	%f612, %f1162, 0f3F13CD3A, %f610;
	fma.rn.f32 	%f111, %f420, 0f3F13CD3A, %f612;
	fma.rn.f32 	%f112, %f420, 0fBF13CD3A, %f612;
	mul.f32 	%f613, %f419, 0f3F13CD3A;
	fma.rn.f32 	%f614, %f1162, 0fBF13CD3A, %f613;
	fma.rn.f32 	%f113, %f420, 0fBF13CD3A, %f614;
	fma.rn.f32 	%f114, %f420, 0f3F13CD3A, %f614;
	fma.rn.f32 	%f615, %f1162, 0f3F13CD3A, %f613;
	fma.rn.f32 	%f115, %f420, 0f3F13CD3A, %f615;
	fma.rn.f32 	%f116, %f420, 0fBF13CD3A, %f615;
	mov.u32 	%r447, 0;
	abs.f32 	%f764, %f96;
	mul.f32 	%f762, %f764, 0f3FDDB3D7;
	abs.f32 	%f788, %f99;
	mul.f32 	%f786, %f788, 0f3FDDB3D7;
	abs.f32 	%f812, %f101;
	mul.f32 	%f810, %f812, 0f3FDDB3D7;
	abs.f32 	%f836, %f102;
	mul.f32 	%f834, %f836, 0f3FDDB3D7;
	abs.f32 	%f860, %f103;
	mul.f32 	%f858, %f860, 0f3FDDB3D7;
	abs.f32 	%f884, %f104;
	mul.f32 	%f882, %f884, 0f3FDDB3D7;
	abs.f32 	%f908, %f105;
	mul.f32 	%f906, %f908, 0f3FDDB3D7;
	abs.f32 	%f932, %f106;
	mul.f32 	%f930, %f932, 0f3FDDB3D7;
	abs.f32 	%f956, %f107;
	mul.f32 	%f954, %f956, 0f3FDDB3D7;
	abs.f32 	%f980, %f109;
	mul.f32 	%f978, %f980, 0f3FDDB3D7;
	abs.f32 	%f1004, %f111;
	mul.f32 	%f1002, %f1004, 0f3FDDB3D7;
	abs.f32 	%f1028, %f112;
	mul.f32 	%f1026, %f1028, 0f3FDDB3D7;
	abs.f32 	%f1052, %f113;
	mul.f32 	%f1050, %f1052, 0f3FDDB3D7;
	abs.f32 	%f1076, %f114;
	mul.f32 	%f1074, %f1076, 0f3FDDB3D7;
	abs.f32 	%f1100, %f115;
	mul.f32 	%f1098, %f1100, 0f3FDDB3D7;
	abs.f32 	%f1124, %f116;
	mul.f32 	%f1122, %f1124, 0f3FDDB3D7;
	mov.u32 	%r2014, %r447;
	mov.f32 	%f1212, %f1186;
	mov.f32 	%f1213, %f1187;
	mov.f32 	%f1214, %f1188;

$L__BB0_18:
	sub.f32 	%f618, %f1188, %f98;
	sub.f32 	%f617, %f1187, %f98;
	add.f32 	%f616, %f1186, %f10;
	mov.f32 	%f619, 0fBF800000;
	mov.f32 	%f624, 0f00000000;
	mov.u32 	%r481, 1;
	mov.u32 	%r484, 2;
	mov.u32 	%r486, 3;
	// begin inline asm
	call(%r448,%r449,%r450,%r451,%r452,%r453,%r454,%r455,%r456,%r457,%r458,%r459,%r460,%r461,%r462,%r463,%r464,%r465,%r466,%r467,%r468,%r469,%r470,%r471,%r472,%r473,%r474,%r475,%r476,%r477,%r478,%r479),_optix_trace_typed_32,(%r447,%rd2,%f616,%f617,%f618,%f619,%f624,%f624,%f624,%f407,%f624,%r481,%r447,%r447,%r484,%r447,%r486,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447,%r447);
	// end inline asm
	mov.b32 	%f125, %r448;
	mov.b32 	%f126, %r449;
	mov.b32 	%f127, %r450;
	abs.f32 	%f626, %f125;
	abs.f32 	%f627, %f126;
	add.f32 	%f628, %f626, %f627;
	abs.f32 	%f629, %f127;
	add.f32 	%f630, %f628, %f629;
	setp.eq.f32 	%p20, %f630, 0f00000000;
	mov.f32 	%f1215, 0f47C34F80;
	@%p20 bra 	$L__BB0_20;

	mul.f32 	%f631, %f126, %f126;
	fma.rn.f32 	%f632, %f125, %f125, %f631;
	fma.rn.f32 	%f633, %f127, %f127, %f632;
	sqrt.rn.f32 	%f634, %f633;
	max.f32 	%f635, %f634, %f10;
	add.f32 	%f636, %f16, %f635;
	setp.lt.f32 	%p21, %f635, 0f47C34F80;
	sub.f32 	%f637, %f1186, %f636;
	fma.rn.f32 	%f638, %f636, 0f00000000, %f1187;
	fma.rn.f32 	%f639, %f636, 0f00000000, %f1188;
	selp.f32 	%f1214, %f639, %f1188, %p21;
	selp.f32 	%f1213, %f638, %f1187, %p21;
	selp.f32 	%f1212, %f637, %f1186, %p21;
	min.f32 	%f1215, %f635, 0f47C34F80;

$L__BB0_20:
	sub.f32 	%f1167, %f1187, %f98;
	sub.f32 	%f640, %f1186, %f10;
	mov.f32 	%f643, 0f3F800000;
	mov.u32 	%r589, 0;
	// begin inline asm
	call(%r519,%r520,%r521,%r522,%r523,%r524,%r525,%r526,%r527,%r528,%r529,%r530,%r531,%r532,%r533,%r534,%r535,%r536,%r537,%r538,%r539,%r540,%r541,%r542,%r543,%r544,%r545,%r546,%r547,%r548,%r549,%r550),_optix_trace_typed_32,(%r589,%rd2,%f640,%f1167,%f618,%f643,%f624,%f624,%f624,%f451,%f624,%r481,%r589,%r589,%r484,%r589,%r486,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589);
	// end inline asm
	mov.b32 	%f136, %r519;
	mov.b32 	%f137, %r520;
	mov.b32 	%f138, %r521;
	abs.f32 	%f649, %f136;
	abs.f32 	%f650, %f137;
	add.f32 	%f651, %f649, %f650;
	abs.f32 	%f652, %f138;
	add.f32 	%f653, %f651, %f652;
	setp.eq.f32 	%p22, %f653, 0f00000000;
	@%p22 bra 	$L__BB0_22;

	mul.f32 	%f654, %f137, %f137;
	fma.rn.f32 	%f655, %f136, %f136, %f654;
	fma.rn.f32 	%f656, %f138, %f138, %f655;
	sqrt.rn.f32 	%f657, %f656;
	max.f32 	%f658, %f657, %f10;
	add.f32 	%f659, %f16, %f658;
	setp.lt.f32 	%p23, %f658, %f1215;
	add.f32 	%f660, %f1186, %f659;
	fma.rn.f32 	%f661, %f659, 0f00000000, %f1187;
	fma.rn.f32 	%f662, %f659, 0f00000000, %f1188;
	selp.f32 	%f1214, %f662, %f1214, %p23;
	selp.f32 	%f1213, %f661, %f1213, %p23;
	selp.f32 	%f1212, %f660, %f1212, %p23;
	selp.f32 	%f1215, %f658, %f1215, %p23;

$L__BB0_22:
	add.f32 	%f664, %f1187, %f10;
	sub.f32 	%f663, %f1186, %f98;
	mov.f32 	%f667, 0fBF800000;
	mov.f32 	%f671, 0f00000000;
	mov.u32 	%r623, 1;
	mov.u32 	%r626, 2;
	mov.u32 	%r628, 3;
	// begin inline asm
	call(%r590,%r591,%r592,%r593,%r594,%r595,%r596,%r597,%r598,%r599,%r600,%r601,%r602,%r603,%r604,%r605,%r606,%r607,%r608,%r609,%r610,%r611,%r612,%r613,%r614,%r615,%r616,%r617,%r618,%r619,%r620,%r621),_optix_trace_typed_32,(%r589,%rd2,%f663,%f664,%f618,%f671,%f667,%f671,%f671,%f483,%f671,%r623,%r589,%r589,%r626,%r589,%r628,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589,%r589);
	// end inline asm
	mov.b32 	%f148, %r590;
	mov.b32 	%f149, %r591;
	mov.b32 	%f150, %r592;
	abs.f32 	%f672, %f148;
	abs.f32 	%f673, %f149;
	add.f32 	%f674, %f672, %f673;
	abs.f32 	%f675, %f150;
	add.f32 	%f676, %f674, %f675;
	setp.eq.f32 	%p24, %f676, 0f00000000;
	@%p24 bra 	$L__BB0_24;

	mul.f32 	%f677, %f149, %f149;
	fma.rn.f32 	%f678, %f148, %f148, %f677;
	fma.rn.f32 	%f679, %f150, %f150, %f678;
	sqrt.rn.f32 	%f680, %f679;
	max.f32 	%f681, %f680, %f10;
	add.f32 	%f682, %f16, %f681;
	setp.lt.f32 	%p25, %f681, %f1215;
	fma.rn.f32 	%f683, %f682, 0f00000000, %f1186;
	sub.f32 	%f684, %f1187, %f682;
	fma.rn.f32 	%f685, %f682, 0f00000000, %f1188;
	selp.f32 	%f1214, %f685, %f1214, %p25;
	selp.f32 	%f1213, %f684, %f1213, %p25;
	selp.f32 	%f1212, %f683, %f1212, %p25;
	selp.f32 	%f1215, %f681, %f1215, %p25;

$L__BB0_24:
	sub.f32 	%f687, %f1187, %f10;
	mov.f32 	%f690, 0f3F800000;
	mov.u32 	%r731, 0;
	// begin inline asm
	call(%r661,%r662,%r663,%r664,%r665,%r666,%r667,%r668,%r669,%r670,%r671,%r672,%r673,%r674,%r675,%r676,%r677,%r678,%r679,%r680,%r681,%r682,%r683,%r684,%r685,%r686,%r687,%r688,%r689,%r690,%r691,%r692),_optix_trace_typed_32,(%r731,%rd2,%f663,%f687,%f618,%f671,%f690,%f671,%f671,%f515,%f671,%r623,%r731,%r731,%r626,%r731,%r628,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731);
	// end inline asm
	mov.b32 	%f159, %r661;
	mov.b32 	%f160, %r662;
	mov.b32 	%f161, %r663;
	abs.f32 	%f695, %f159;
	abs.f32 	%f696, %f160;
	add.f32 	%f697, %f695, %f696;
	abs.f32 	%f698, %f161;
	add.f32 	%f699, %f697, %f698;
	setp.eq.f32 	%p26, %f699, 0f00000000;
	@%p26 bra 	$L__BB0_26;

	mul.f32 	%f700, %f160, %f160;
	fma.rn.f32 	%f701, %f159, %f159, %f700;
	fma.rn.f32 	%f702, %f161, %f161, %f701;
	sqrt.rn.f32 	%f703, %f702;
	max.f32 	%f704, %f703, %f10;
	add.f32 	%f705, %f16, %f704;
	setp.lt.f32 	%p27, %f704, %f1215;
	fma.rn.f32 	%f706, %f705, 0f00000000, %f1186;
	add.f32 	%f707, %f1187, %f705;
	fma.rn.f32 	%f708, %f705, 0f00000000, %f1188;
	selp.f32 	%f1214, %f708, %f1214, %p27;
	selp.f32 	%f1213, %f707, %f1213, %p27;
	selp.f32 	%f1212, %f706, %f1212, %p27;
	selp.f32 	%f1215, %f704, %f1215, %p27;

$L__BB0_26:
	sub.f32 	%f1168, %f1187, %f98;
	add.f32 	%f711, %f1188, %f10;
	mov.f32 	%f714, 0fBF800000;
	mov.f32 	%f717, 0f00000000;
	mov.u32 	%r765, 1;
	mov.u32 	%r768, 2;
	mov.u32 	%r770, 3;
	// begin inline asm
	call(%r732,%r733,%r734,%r735,%r736,%r737,%r738,%r739,%r740,%r741,%r742,%r743,%r744,%r745,%r746,%r747,%r748,%r749,%r750,%r751,%r752,%r753,%r754,%r755,%r756,%r757,%r758,%r759,%r760,%r761,%r762,%r763),_optix_trace_typed_32,(%r731,%rd2,%f663,%f1168,%f711,%f717,%f717,%f714,%f717,%f547,%f717,%r765,%r731,%r731,%r768,%r731,%r770,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731,%r731);
	// end inline asm
	mov.b32 	%f170, %r732;
	mov.b32 	%f171, %r733;
	mov.b32 	%f172, %r734;
	abs.f32 	%f718, %f170;
	abs.f32 	%f719, %f171;
	add.f32 	%f720, %f718, %f719;
	abs.f32 	%f721, %f172;
	add.f32 	%f722, %f720, %f721;
	setp.eq.f32 	%p28, %f722, 0f00000000;
	@%p28 bra 	$L__BB0_28;

	mul.f32 	%f723, %f171, %f171;
	fma.rn.f32 	%f724, %f170, %f170, %f723;
	fma.rn.f32 	%f725, %f172, %f172, %f724;
	sqrt.rn.f32 	%f726, %f725;
	max.f32 	%f727, %f726, %f10;
	add.f32 	%f728, %f16, %f727;
	setp.lt.f32 	%p29, %f727, %f1215;
	fma.rn.f32 	%f729, %f728, 0f00000000, %f1186;
	fma.rn.f32 	%f730, %f728, 0f00000000, %f1187;
	sub.f32 	%f731, %f1188, %f728;
	selp.f32 	%f1214, %f731, %f1214, %p29;
	selp.f32 	%f1213, %f730, %f1213, %p29;
	selp.f32 	%f1212, %f729, %f1212, %p29;
	selp.f32 	%f1215, %f727, %f1215, %p29;

$L__BB0_28:
	sub.f32 	%f1169, %f1187, %f98;
	sub.f32 	%f734, %f1188, %f10;
	mov.f32 	%f737, 0f3F800000;
	mov.u32 	%r873, 0;
	// begin inline asm
	call(%r803,%r804,%r805,%r806,%r807,%r808,%r809,%r810,%r811,%r812,%r813,%r814,%r815,%r816,%r817,%r818,%r819,%r820,%r821,%r822,%r823,%r824,%r825,%r826,%r827,%r828,%r829,%r830,%r831,%r832,%r833,%r834),_optix_trace_typed_32,(%r873,%rd2,%f663,%f1169,%f734,%f717,%f717,%f737,%f717,%f578,%f717,%r765,%r873,%r873,%r768,%r873,%r770,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873);
	// end inline asm
	mov.b32 	%f181, %r803;
	mov.b32 	%f182, %r804;
	mov.b32 	%f183, %r805;
	abs.f32 	%f741, %f181;
	abs.f32 	%f742, %f182;
	add.f32 	%f743, %f741, %f742;
	abs.f32 	%f744, %f183;
	add.f32 	%f745, %f743, %f744;
	setp.eq.f32 	%p30, %f745, 0f00000000;
	@%p30 bra 	$L__BB0_30;

	mul.f32 	%f746, %f182, %f182;
	fma.rn.f32 	%f747, %f181, %f181, %f746;
	fma.rn.f32 	%f748, %f183, %f183, %f747;
	sqrt.rn.f32 	%f749, %f748;
	max.f32 	%f750, %f749, %f10;
	add.f32 	%f751, %f16, %f750;
	setp.lt.f32 	%p31, %f750, %f1215;
	fma.rn.f32 	%f752, %f751, 0f00000000, %f1186;
	fma.rn.f32 	%f753, %f751, 0f00000000, %f1187;
	add.f32 	%f754, %f1188, %f751;
	selp.f32 	%f1214, %f754, %f1214, %p31;
	selp.f32 	%f1213, %f753, %f1213, %p31;
	selp.f32 	%f1212, %f752, %f1212, %p31;
	selp.f32 	%f1215, %f750, %f1215, %p31;

$L__BB0_30:
	sub.f32 	%f756, %f1187, %f97;
	sub.f32 	%f755, %f1186, %f97;
	mov.f32 	%f759, 0fBF3504F3;
	mov.f32 	%f763, 0f00000000;
	mov.u32 	%r907, 1;
	mov.u32 	%r910, 2;
	mov.u32 	%r912, 3;
	// begin inline asm
	call(%r874,%r875,%r876,%r877,%r878,%r879,%r880,%r881,%r882,%r883,%r884,%r885,%r886,%r887,%r888,%r889,%r890,%r891,%r892,%r893,%r894,%r895,%r896,%r897,%r898,%r899,%r900,%r901,%r902,%r903,%r904,%r905),_optix_trace_typed_32,(%r873,%rd2,%f755,%f756,%f618,%f759,%f759,%f763,%f763,%f762,%f763,%r907,%r873,%r873,%r910,%r873,%r912,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873,%r873);
	// end inline asm
	mov.b32 	%f195, %r874;
	mov.b32 	%f196, %r875;
	mov.b32 	%f197, %r876;
	abs.f32 	%f765, %f195;
	abs.f32 	%f766, %f196;
	add.f32 	%f767, %f765, %f766;
	abs.f32 	%f768, %f197;
	add.f32 	%f769, %f767, %f768;
	setp.eq.f32 	%p32, %f769, 0f00000000;
	@%p32 bra 	$L__BB0_32;

	mul.f32 	%f770, %f196, %f196;
	fma.rn.f32 	%f771, %f195, %f195, %f770;
	fma.rn.f32 	%f772, %f197, %f197, %f771;
	sqrt.rn.f32 	%f773, %f772;
	max.f32 	%f774, %f773, %f10;
	add.f32 	%f775, %f16, %f774;
	setp.lt.f32 	%p33, %f774, %f1215;
	fma.rn.f32 	%f776, %f775, 0fBF3504F3, %f1186;
	fma.rn.f32 	%f777, %f775, 0fBF3504F3, %f1187;
	fma.rn.f32 	%f778, %f775, 0f00000000, %f1188;
	selp.f32 	%f1214, %f778, %f1214, %p33;
	selp.f32 	%f1213, %f777, %f1213, %p33;
	selp.f32 	%f1212, %f776, %f1212, %p33;
	selp.f32 	%f1215, %f774, %f1215, %p33;

$L__BB0_32:
	sub.f32 	%f780, %f1187, %f100;
	mov.f32 	%f783, 0f3F3504F3;
	mov.u32 	%r1015, 0;
	// begin inline asm
	call(%r945,%r946,%r947,%r948,%r949,%r950,%r951,%r952,%r953,%r954,%r955,%r956,%r957,%r958,%r959,%r960,%r961,%r962,%r963,%r964,%r965,%r966,%r967,%r968,%r969,%r970,%r971,%r972,%r973,%r974,%r975,%r976),_optix_trace_typed_32,(%r1015,%rd2,%f755,%f780,%f618,%f759,%f783,%f763,%f763,%f786,%f763,%r907,%r1015,%r1015,%r910,%r1015,%r912,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015);
	// end inline asm
	mov.b32 	%f207, %r945;
	mov.b32 	%f208, %r946;
	mov.b32 	%f209, %r947;
	abs.f32 	%f789, %f207;
	abs.f32 	%f790, %f208;
	add.f32 	%f791, %f789, %f790;
	abs.f32 	%f792, %f209;
	add.f32 	%f793, %f791, %f792;
	setp.eq.f32 	%p34, %f793, 0f00000000;
	@%p34 bra 	$L__BB0_34;

	mul.f32 	%f794, %f208, %f208;
	fma.rn.f32 	%f795, %f207, %f207, %f794;
	fma.rn.f32 	%f796, %f209, %f209, %f795;
	sqrt.rn.f32 	%f797, %f796;
	max.f32 	%f798, %f797, %f10;
	add.f32 	%f799, %f16, %f798;
	setp.lt.f32 	%p35, %f798, %f1215;
	fma.rn.f32 	%f800, %f799, 0fBF3504F3, %f1186;
	fma.rn.f32 	%f801, %f799, 0f3F3504F3, %f1187;
	fma.rn.f32 	%f802, %f799, 0f00000000, %f1188;
	selp.f32 	%f1214, %f802, %f1214, %p35;
	selp.f32 	%f1213, %f801, %f1213, %p35;
	selp.f32 	%f1212, %f800, %f1212, %p35;
	selp.f32 	%f1215, %f798, %f1215, %p35;

$L__BB0_34:
	sub.f32 	%f1173, %f1187, %f100;
	sub.f32 	%f803, %f1186, %f100;
	mov.f32 	%f811, 0f00000000;
	mov.u32 	%r1049, 1;
	mov.u32 	%r1052, 2;
	mov.u32 	%r1054, 3;
	// begin inline asm
	call(%r1016,%r1017,%r1018,%r1019,%r1020,%r1021,%r1022,%r1023,%r1024,%r1025,%r1026,%r1027,%r1028,%r1029,%r1030,%r1031,%r1032,%r1033,%r1034,%r1035,%r1036,%r1037,%r1038,%r1039,%r1040,%r1041,%r1042,%r1043,%r1044,%r1045,%r1046,%r1047),_optix_trace_typed_32,(%r1015,%rd2,%f803,%f1173,%f618,%f783,%f783,%f811,%f811,%f810,%f811,%r1049,%r1015,%r1015,%r1052,%r1015,%r1054,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015,%r1015);
	// end inline asm
	mov.b32 	%f219, %r1016;
	mov.b32 	%f220, %r1017;
	mov.b32 	%f221, %r1018;
	abs.f32 	%f813, %f219;
	abs.f32 	%f814, %f220;
	add.f32 	%f815, %f813, %f814;
	abs.f32 	%f816, %f221;
	add.f32 	%f817, %f815, %f816;
	setp.eq.f32 	%p36, %f817, 0f00000000;
	@%p36 bra 	$L__BB0_36;

	mul.f32 	%f818, %f220, %f220;
	fma.rn.f32 	%f819, %f219, %f219, %f818;
	fma.rn.f32 	%f820, %f221, %f221, %f819;
	sqrt.rn.f32 	%f821, %f820;
	max.f32 	%f822, %f821, %f10;
	add.f32 	%f823, %f16, %f822;
	setp.lt.f32 	%p37, %f822, %f1215;
	fma.rn.f32 	%f824, %f823, 0f3F3504F3, %f1186;
	fma.rn.f32 	%f825, %f823, 0f3F3504F3, %f1187;
	fma.rn.f32 	%f826, %f823, 0f00000000, %f1188;
	selp.f32 	%f1214, %f826, %f1214, %p37;
	selp.f32 	%f1213, %f825, %f1213, %p37;
	selp.f32 	%f1212, %f824, %f1212, %p37;
	selp.f32 	%f1215, %f822, %f1215, %p37;

$L__BB0_36:
	sub.f32 	%f1170, %f1187, %f97;
	mov.f32 	%f830, 0f3F3504F3;
	mov.f32 	%f831, 0fBF3504F3;
	mov.u32 	%r1157, 0;
	// begin inline asm
	call(%r1087,%r1088,%r1089,%r1090,%r1091,%r1092,%r1093,%r1094,%r1095,%r1096,%r1097,%r1098,%r1099,%r1100,%r1101,%r1102,%r1103,%r1104,%r1105,%r1106,%r1107,%r1108,%r1109,%r1110,%r1111,%r1112,%r1113,%r1114,%r1115,%r1116,%r1117,%r1118),_optix_trace_typed_32,(%r1157,%rd2,%f803,%f1170,%f618,%f830,%f831,%f811,%f811,%f834,%f811,%r1049,%r1157,%r1157,%r1052,%r1157,%r1054,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157);
	// end inline asm
	mov.b32 	%f230, %r1087;
	mov.b32 	%f231, %r1088;
	mov.b32 	%f232, %r1089;
	abs.f32 	%f837, %f230;
	abs.f32 	%f838, %f231;
	add.f32 	%f839, %f837, %f838;
	abs.f32 	%f840, %f232;
	add.f32 	%f841, %f839, %f840;
	setp.eq.f32 	%p38, %f841, 0f00000000;
	@%p38 bra 	$L__BB0_38;

	mul.f32 	%f842, %f231, %f231;
	fma.rn.f32 	%f843, %f230, %f230, %f842;
	fma.rn.f32 	%f844, %f232, %f232, %f843;
	sqrt.rn.f32 	%f845, %f844;
	max.f32 	%f846, %f845, %f10;
	add.f32 	%f847, %f16, %f846;
	setp.lt.f32 	%p39, %f846, %f1215;
	fma.rn.f32 	%f848, %f847, 0f3F3504F3, %f1186;
	fma.rn.f32 	%f849, %f847, 0fBF3504F3, %f1187;
	fma.rn.f32 	%f850, %f847, 0f00000000, %f1188;
	selp.f32 	%f1214, %f850, %f1214, %p39;
	selp.f32 	%f1213, %f849, %f1213, %p39;
	selp.f32 	%f1212, %f848, %f1212, %p39;
	selp.f32 	%f1215, %f846, %f1215, %p39;

$L__BB0_38:
	sub.f32 	%f1171, %f1187, %f97;
	sub.f32 	%f853, %f1188, %f97;
	mov.f32 	%f859, 0f00000000;
	mov.u32 	%r1191, 1;
	mov.u32 	%r1194, 2;
	mov.u32 	%r1196, 3;
	// begin inline asm
	call(%r1158,%r1159,%r1160,%r1161,%r1162,%r1163,%r1164,%r1165,%r1166,%r1167,%r1168,%r1169,%r1170,%r1171,%r1172,%r1173,%r1174,%r1175,%r1176,%r1177,%r1178,%r1179,%r1180,%r1181,%r1182,%r1183,%r1184,%r1185,%r1186,%r1187,%r1188,%r1189),_optix_trace_typed_32,(%r1157,%rd2,%f663,%f1171,%f853,%f859,%f831,%f831,%f859,%f858,%f859,%r1191,%r1157,%r1157,%r1194,%r1157,%r1196,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157,%r1157);
	// end inline asm
	mov.b32 	%f243, %r1158;
	mov.b32 	%f244, %r1159;
	mov.b32 	%f245, %r1160;
	abs.f32 	%f861, %f243;
	abs.f32 	%f862, %f244;
	add.f32 	%f863, %f861, %f862;
	abs.f32 	%f864, %f245;
	add.f32 	%f865, %f863, %f864;
	setp.eq.f32 	%p40, %f865, 0f00000000;
	@%p40 bra 	$L__BB0_40;

	mul.f32 	%f866, %f244, %f244;
	fma.rn.f32 	%f867, %f243, %f243, %f866;
	fma.rn.f32 	%f868, %f245, %f245, %f867;
	sqrt.rn.f32 	%f869, %f868;
	max.f32 	%f870, %f869, %f10;
	add.f32 	%f871, %f16, %f870;
	setp.lt.f32 	%p41, %f870, %f1215;
	fma.rn.f32 	%f872, %f871, 0f00000000, %f1186;
	fma.rn.f32 	%f873, %f871, 0fBF3504F3, %f1187;
	fma.rn.f32 	%f874, %f871, 0fBF3504F3, %f1188;
	selp.f32 	%f1214, %f874, %f1214, %p41;
	selp.f32 	%f1213, %f873, %f1213, %p41;
	selp.f32 	%f1212, %f872, %f1212, %p41;
	selp.f32 	%f1215, %f870, %f1215, %p41;

$L__BB0_40:
	sub.f32 	%f1172, %f1187, %f97;
	sub.f32 	%f877, %f1188, %f100;
	mov.f32 	%f879, 0fBF3504F3;
	mov.f32 	%f880, 0f3F3504F3;
	mov.u32 	%r1299, 0;
	// begin inline asm
	call(%r1229,%r1230,%r1231,%r1232,%r1233,%r1234,%r1235,%r1236,%r1237,%r1238,%r1239,%r1240,%r1241,%r1242,%r1243,%r1244,%r1245,%r1246,%r1247,%r1248,%r1249,%r1250,%r1251,%r1252,%r1253,%r1254,%r1255,%r1256,%r1257,%r1258,%r1259,%r1260),_optix_trace_typed_32,(%r1299,%rd2,%f663,%f1172,%f877,%f859,%f879,%f880,%f859,%f882,%f859,%r1191,%r1299,%r1299,%r1194,%r1299,%r1196,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299);
	// end inline asm
	mov.b32 	%f255, %r1229;
	mov.b32 	%f256, %r1230;
	mov.b32 	%f257, %r1231;
	abs.f32 	%f885, %f255;
	abs.f32 	%f886, %f256;
	add.f32 	%f887, %f885, %f886;
	abs.f32 	%f888, %f257;
	add.f32 	%f889, %f887, %f888;
	setp.eq.f32 	%p42, %f889, 0f00000000;
	@%p42 bra 	$L__BB0_42;

	mul.f32 	%f890, %f256, %f256;
	fma.rn.f32 	%f891, %f255, %f255, %f890;
	fma.rn.f32 	%f892, %f257, %f257, %f891;
	sqrt.rn.f32 	%f893, %f892;
	max.f32 	%f894, %f893, %f10;
	add.f32 	%f895, %f16, %f894;
	setp.lt.f32 	%p43, %f894, %f1215;
	fma.rn.f32 	%f896, %f895, 0f00000000, %f1186;
	fma.rn.f32 	%f897, %f895, 0fBF3504F3, %f1187;
	fma.rn.f32 	%f898, %f895, 0f3F3504F3, %f1188;
	selp.f32 	%f1214, %f898, %f1214, %p43;
	selp.f32 	%f1213, %f897, %f1213, %p43;
	selp.f32 	%f1212, %f896, %f1212, %p43;
	selp.f32 	%f1215, %f894, %f1215, %p43;

$L__BB0_42:
	sub.f32 	%f1174, %f1187, %f100;
	mov.f32 	%f907, 0f00000000;
	mov.u32 	%r1333, 1;
	mov.u32 	%r1336, 2;
	mov.u32 	%r1338, 3;
	// begin inline asm
	call(%r1300,%r1301,%r1302,%r1303,%r1304,%r1305,%r1306,%r1307,%r1308,%r1309,%r1310,%r1311,%r1312,%r1313,%r1314,%r1315,%r1316,%r1317,%r1318,%r1319,%r1320,%r1321,%r1322,%r1323,%r1324,%r1325,%r1326,%r1327,%r1328,%r1329,%r1330,%r1331),_optix_trace_typed_32,(%r1299,%rd2,%f663,%f1174,%f877,%f907,%f880,%f880,%f907,%f906,%f907,%r1333,%r1299,%r1299,%r1336,%r1299,%r1338,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299,%r1299);
	// end inline asm
	mov.b32 	%f266, %r1300;
	mov.b32 	%f267, %r1301;
	mov.b32 	%f268, %r1302;
	abs.f32 	%f909, %f266;
	abs.f32 	%f910, %f267;
	add.f32 	%f911, %f909, %f910;
	abs.f32 	%f912, %f268;
	add.f32 	%f913, %f911, %f912;
	setp.eq.f32 	%p44, %f913, 0f00000000;
	@%p44 bra 	$L__BB0_44;

	mul.f32 	%f914, %f267, %f267;
	fma.rn.f32 	%f915, %f266, %f266, %f914;
	fma.rn.f32 	%f916, %f268, %f268, %f915;
	sqrt.rn.f32 	%f917, %f916;
	max.f32 	%f918, %f917, %f10;
	add.f32 	%f919, %f16, %f918;
	setp.lt.f32 	%p45, %f918, %f1215;
	fma.rn.f32 	%f920, %f919, 0f00000000, %f1186;
	fma.rn.f32 	%f921, %f919, 0f3F3504F3, %f1187;
	fma.rn.f32 	%f922, %f919, 0f3F3504F3, %f1188;
	selp.f32 	%f1214, %f922, %f1214, %p45;
	selp.f32 	%f1213, %f921, %f1213, %p45;
	selp.f32 	%f1212, %f920, %f1212, %p45;
	selp.f32 	%f1215, %f918, %f1215, %p45;

$L__BB0_44:
	sub.f32 	%f1176, %f1188, %f97;
	sub.f32 	%f1175, %f1187, %f100;
	mov.f32 	%f927, 0f3F3504F3;
	mov.f32 	%f928, 0fBF3504F3;
	mov.u32 	%r1441, 0;
	// begin inline asm
	call(%r1371,%r1372,%r1373,%r1374,%r1375,%r1376,%r1377,%r1378,%r1379,%r1380,%r1381,%r1382,%r1383,%r1384,%r1385,%r1386,%r1387,%r1388,%r1389,%r1390,%r1391,%r1392,%r1393,%r1394,%r1395,%r1396,%r1397,%r1398,%r1399,%r1400,%r1401,%r1402),_optix_trace_typed_32,(%r1441,%rd2,%f663,%f1175,%f1176,%f907,%f927,%f928,%f907,%f930,%f907,%r1333,%r1441,%r1441,%r1336,%r1441,%r1338,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441);
	// end inline asm
	mov.b32 	%f277, %r1371;
	mov.b32 	%f278, %r1372;
	mov.b32 	%f279, %r1373;
	abs.f32 	%f933, %f277;
	abs.f32 	%f934, %f278;
	add.f32 	%f935, %f933, %f934;
	abs.f32 	%f936, %f279;
	add.f32 	%f937, %f935, %f936;
	setp.eq.f32 	%p46, %f937, 0f00000000;
	@%p46 bra 	$L__BB0_46;

	mul.f32 	%f938, %f278, %f278;
	fma.rn.f32 	%f939, %f277, %f277, %f938;
	fma.rn.f32 	%f940, %f279, %f279, %f939;
	sqrt.rn.f32 	%f941, %f940;
	max.f32 	%f942, %f941, %f10;
	add.f32 	%f943, %f16, %f942;
	setp.lt.f32 	%p47, %f942, %f1215;
	fma.rn.f32 	%f944, %f943, 0f00000000, %f1186;
	fma.rn.f32 	%f945, %f943, 0f3F3504F3, %f1187;
	fma.rn.f32 	%f946, %f943, 0fBF3504F3, %f1188;
	selp.f32 	%f1214, %f946, %f1214, %p47;
	selp.f32 	%f1213, %f945, %f1213, %p47;
	selp.f32 	%f1212, %f944, %f1212, %p47;
	selp.f32 	%f1215, %f942, %f1215, %p47;

$L__BB0_46:
	sub.f32 	%f949, %f1188, %f108;
	sub.f32 	%f948, %f1187, %f108;
	sub.f32 	%f947, %f1186, %f108;
	mov.f32 	%f952, 0fBF13CD3A;
	mov.f32 	%f955, 0f00000000;
	mov.u32 	%r1475, 1;
	mov.u32 	%r1478, 2;
	mov.u32 	%r1480, 3;
	// begin inline asm
	call(%r1442,%r1443,%r1444,%r1445,%r1446,%r1447,%r1448,%r1449,%r1450,%r1451,%r1452,%r1453,%r1454,%r1455,%r1456,%r1457,%r1458,%r1459,%r1460,%r1461,%r1462,%r1463,%r1464,%r1465,%r1466,%r1467,%r1468,%r1469,%r1470,%r1471,%r1472,%r1473),_optix_trace_typed_32,(%r1441,%rd2,%f947,%f948,%f949,%f952,%f952,%f952,%f955,%f954,%f955,%r1475,%r1441,%r1441,%r1478,%r1441,%r1480,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441,%r1441);
	// end inline asm
	mov.b32 	%f291, %r1442;
	mov.b32 	%f292, %r1443;
	mov.b32 	%f293, %r1444;
	abs.f32 	%f957, %f291;
	abs.f32 	%f958, %f292;
	add.f32 	%f959, %f957, %f958;
	abs.f32 	%f960, %f293;
	add.f32 	%f961, %f959, %f960;
	setp.eq.f32 	%p48, %f961, 0f00000000;
	@%p48 bra 	$L__BB0_48;

	mul.f32 	%f962, %f292, %f292;
	fma.rn.f32 	%f963, %f291, %f291, %f962;
	fma.rn.f32 	%f964, %f293, %f293, %f963;
	sqrt.rn.f32 	%f965, %f964;
	max.f32 	%f966, %f965, %f10;
	add.f32 	%f967, %f16, %f966;
	setp.lt.f32 	%p49, %f966, %f1215;
	fma.rn.f32 	%f968, %f967, 0fBF13CD3A, %f1186;
	fma.rn.f32 	%f969, %f967, 0fBF13CD3A, %f1187;
	fma.rn.f32 	%f970, %f967, 0fBF13CD3A, %f1188;
	selp.f32 	%f1214, %f970, %f1214, %p49;
	selp.f32 	%f1213, %f969, %f1213, %p49;
	selp.f32 	%f1212, %f968, %f1212, %p49;
	selp.f32 	%f1215, %f966, %f1215, %p49;

$L__BB0_48:
	sub.f32 	%f1177, %f1187, %f108;
	sub.f32 	%f973, %f1188, %f110;
	mov.f32 	%f976, 0f3F13CD3A;
	mov.u32 	%r1583, 0;
	// begin inline asm
	call(%r1513,%r1514,%r1515,%r1516,%r1517,%r1518,%r1519,%r1520,%r1521,%r1522,%r1523,%r1524,%r1525,%r1526,%r1527,%r1528,%r1529,%r1530,%r1531,%r1532,%r1533,%r1534,%r1535,%r1536,%r1537,%r1538,%r1539,%r1540,%r1541,%r1542,%r1543,%r1544),_optix_trace_typed_32,(%r1583,%rd2,%f947,%f1177,%f973,%f952,%f952,%f976,%f955,%f978,%f955,%r1475,%r1583,%r1583,%r1478,%r1583,%r1480,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583);
	// end inline asm
	mov.b32 	%f303, %r1513;
	mov.b32 	%f304, %r1514;
	mov.b32 	%f305, %r1515;
	abs.f32 	%f981, %f303;
	abs.f32 	%f982, %f304;
	add.f32 	%f983, %f981, %f982;
	abs.f32 	%f984, %f305;
	add.f32 	%f985, %f983, %f984;
	setp.eq.f32 	%p50, %f985, 0f00000000;
	@%p50 bra 	$L__BB0_50;

	mul.f32 	%f986, %f304, %f304;
	fma.rn.f32 	%f987, %f303, %f303, %f986;
	fma.rn.f32 	%f988, %f305, %f305, %f987;
	sqrt.rn.f32 	%f989, %f988;
	max.f32 	%f990, %f989, %f10;
	add.f32 	%f991, %f16, %f990;
	setp.lt.f32 	%p51, %f990, %f1215;
	fma.rn.f32 	%f992, %f991, 0fBF13CD3A, %f1186;
	fma.rn.f32 	%f993, %f991, 0fBF13CD3A, %f1187;
	fma.rn.f32 	%f994, %f991, 0f3F13CD3A, %f1188;
	selp.f32 	%f1214, %f994, %f1214, %p51;
	selp.f32 	%f1213, %f993, %f1213, %p51;
	selp.f32 	%f1212, %f992, %f1212, %p51;
	selp.f32 	%f1215, %f990, %f1215, %p51;

$L__BB0_50:
	sub.f32 	%f1178, %f1187, %f108;
	sub.f32 	%f995, %f1186, %f110;
	mov.f32 	%f999, 0fBF13CD3A;
	mov.f32 	%f1003, 0f00000000;
	mov.u32 	%r1617, 1;
	mov.u32 	%r1620, 2;
	mov.u32 	%r1622, 3;
	// begin inline asm
	call(%r1584,%r1585,%r1586,%r1587,%r1588,%r1589,%r1590,%r1591,%r1592,%r1593,%r1594,%r1595,%r1596,%r1597,%r1598,%r1599,%r1600,%r1601,%r1602,%r1603,%r1604,%r1605,%r1606,%r1607,%r1608,%r1609,%r1610,%r1611,%r1612,%r1613,%r1614,%r1615),_optix_trace_typed_32,(%r1583,%rd2,%f995,%f1178,%f973,%f976,%f999,%f976,%f1003,%f1002,%f1003,%r1617,%r1583,%r1583,%r1620,%r1583,%r1622,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583,%r1583);
	// end inline asm
	mov.b32 	%f315, %r1584;
	mov.b32 	%f316, %r1585;
	mov.b32 	%f317, %r1586;
	abs.f32 	%f1005, %f315;
	abs.f32 	%f1006, %f316;
	add.f32 	%f1007, %f1005, %f1006;
	abs.f32 	%f1008, %f317;
	add.f32 	%f1009, %f1007, %f1008;
	setp.eq.f32 	%p52, %f1009, 0f00000000;
	@%p52 bra 	$L__BB0_52;

	mul.f32 	%f1010, %f316, %f316;
	fma.rn.f32 	%f1011, %f315, %f315, %f1010;
	fma.rn.f32 	%f1012, %f317, %f317, %f1011;
	sqrt.rn.f32 	%f1013, %f1012;
	max.f32 	%f1014, %f1013, %f10;
	add.f32 	%f1015, %f16, %f1014;
	setp.lt.f32 	%p53, %f1014, %f1215;
	fma.rn.f32 	%f1016, %f1015, 0f3F13CD3A, %f1186;
	fma.rn.f32 	%f1017, %f1015, 0fBF13CD3A, %f1187;
	fma.rn.f32 	%f1018, %f1015, 0f3F13CD3A, %f1188;
	selp.f32 	%f1214, %f1018, %f1214, %p53;
	selp.f32 	%f1213, %f1017, %f1213, %p53;
	selp.f32 	%f1212, %f1016, %f1212, %p53;
	selp.f32 	%f1215, %f1014, %f1215, %p53;

$L__BB0_52:
	sub.f32 	%f1143, %f1188, %f108;
	sub.f32 	%f1142, %f1186, %f110;
	sub.f32 	%f1141, %f1187, %f108;
	mov.f32 	%f1022, 0f3F13CD3A;
	mov.u32 	%r1725, 0;
	// begin inline asm
	call(%r1655,%r1656,%r1657,%r1658,%r1659,%r1660,%r1661,%r1662,%r1663,%r1664,%r1665,%r1666,%r1667,%r1668,%r1669,%r1670,%r1671,%r1672,%r1673,%r1674,%r1675,%r1676,%r1677,%r1678,%r1679,%r1680,%r1681,%r1682,%r1683,%r1684,%r1685,%r1686),_optix_trace_typed_32,(%r1725,%rd2,%f1142,%f1141,%f1143,%f1022,%f999,%f999,%f1003,%f1026,%f1003,%r1617,%r1725,%r1725,%r1620,%r1725,%r1622,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725);
	// end inline asm
	mov.b32 	%f326, %r1655;
	mov.b32 	%f327, %r1656;
	mov.b32 	%f328, %r1657;
	abs.f32 	%f1029, %f326;
	abs.f32 	%f1030, %f327;
	add.f32 	%f1031, %f1029, %f1030;
	abs.f32 	%f1032, %f328;
	add.f32 	%f1033, %f1031, %f1032;
	setp.eq.f32 	%p54, %f1033, 0f00000000;
	@%p54 bra 	$L__BB0_54;

	mul.f32 	%f1034, %f327, %f327;
	fma.rn.f32 	%f1035, %f326, %f326, %f1034;
	fma.rn.f32 	%f1036, %f328, %f328, %f1035;
	sqrt.rn.f32 	%f1037, %f1036;
	max.f32 	%f1038, %f1037, %f10;
	add.f32 	%f1039, %f16, %f1038;
	setp.lt.f32 	%p55, %f1038, %f1215;
	fma.rn.f32 	%f1040, %f1039, 0f3F13CD3A, %f1186;
	fma.rn.f32 	%f1041, %f1039, 0fBF13CD3A, %f1187;
	fma.rn.f32 	%f1042, %f1039, 0fBF13CD3A, %f1188;
	selp.f32 	%f1214, %f1042, %f1214, %p55;
	selp.f32 	%f1213, %f1041, %f1213, %p55;
	selp.f32 	%f1212, %f1040, %f1212, %p55;
	selp.f32 	%f1215, %f1038, %f1215, %p55;

$L__BB0_54:
	sub.f32 	%f1145, %f1188, %f108;
	sub.f32 	%f1144, %f1186, %f108;
	sub.f32 	%f1044, %f1187, %f110;
	mov.f32 	%f1048, 0fBF13CD3A;
	mov.f32 	%f1051, 0f00000000;
	mov.u32 	%r1759, 1;
	mov.u32 	%r1762, 2;
	mov.u32 	%r1764, 3;
	// begin inline asm
	call(%r1726,%r1727,%r1728,%r1729,%r1730,%r1731,%r1732,%r1733,%r1734,%r1735,%r1736,%r1737,%r1738,%r1739,%r1740,%r1741,%r1742,%r1743,%r1744,%r1745,%r1746,%r1747,%r1748,%r1749,%r1750,%r1751,%r1752,%r1753,%r1754,%r1755,%r1756,%r1757),_optix_trace_typed_32,(%r1725,%rd2,%f1144,%f1044,%f1145,%f1048,%f1022,%f1048,%f1051,%f1050,%f1051,%r1759,%r1725,%r1725,%r1762,%r1725,%r1764,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725,%r1725);
	// end inline asm
	mov.b32 	%f338, %r1726;
	mov.b32 	%f339, %r1727;
	mov.b32 	%f340, %r1728;
	abs.f32 	%f1053, %f338;
	abs.f32 	%f1054, %f339;
	add.f32 	%f1055, %f1053, %f1054;
	abs.f32 	%f1056, %f340;
	add.f32 	%f1057, %f1055, %f1056;
	setp.eq.f32 	%p56, %f1057, 0f00000000;
	@%p56 bra 	$L__BB0_56;

	mul.f32 	%f1058, %f339, %f339;
	fma.rn.f32 	%f1059, %f338, %f338, %f1058;
	fma.rn.f32 	%f1060, %f340, %f340, %f1059;
	sqrt.rn.f32 	%f1061, %f1060;
	max.f32 	%f1062, %f1061, %f10;
	add.f32 	%f1063, %f16, %f1062;
	setp.lt.f32 	%p57, %f1062, %f1215;
	fma.rn.f32 	%f1064, %f1063, 0fBF13CD3A, %f1186;
	fma.rn.f32 	%f1065, %f1063, 0f3F13CD3A, %f1187;
	fma.rn.f32 	%f1066, %f1063, 0fBF13CD3A, %f1188;
	selp.f32 	%f1214, %f1066, %f1214, %p57;
	selp.f32 	%f1213, %f1065, %f1213, %p57;
	selp.f32 	%f1212, %f1064, %f1212, %p57;
	selp.f32 	%f1215, %f1062, %f1215, %p57;

$L__BB0_56:
	sub.f32 	%f1152, %f1187, %f110;
	sub.f32 	%f1147, %f1188, %f110;
	sub.f32 	%f1146, %f1186, %f108;
	mov.f32 	%f1072, 0f3F13CD3A;
	mov.u32 	%r1867, 0;
	// begin inline asm
	call(%r1797,%r1798,%r1799,%r1800,%r1801,%r1802,%r1803,%r1804,%r1805,%r1806,%r1807,%r1808,%r1809,%r1810,%r1811,%r1812,%r1813,%r1814,%r1815,%r1816,%r1817,%r1818,%r1819,%r1820,%r1821,%r1822,%r1823,%r1824,%r1825,%r1826,%r1827,%r1828),_optix_trace_typed_32,(%r1867,%rd2,%f1146,%f1152,%f1147,%f1048,%f1072,%f1072,%f1051,%f1074,%f1051,%r1759,%r1867,%r1867,%r1762,%r1867,%r1764,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867);
	// end inline asm
	mov.b32 	%f349, %r1797;
	mov.b32 	%f350, %r1798;
	mov.b32 	%f351, %r1799;
	abs.f32 	%f1077, %f349;
	abs.f32 	%f1078, %f350;
	add.f32 	%f1079, %f1077, %f1078;
	abs.f32 	%f1080, %f351;
	add.f32 	%f1081, %f1079, %f1080;
	setp.eq.f32 	%p58, %f1081, 0f00000000;
	@%p58 bra 	$L__BB0_58;

	mul.f32 	%f1082, %f350, %f350;
	fma.rn.f32 	%f1083, %f349, %f349, %f1082;
	fma.rn.f32 	%f1084, %f351, %f351, %f1083;
	sqrt.rn.f32 	%f1085, %f1084;
	max.f32 	%f1086, %f1085, %f10;
	add.f32 	%f1087, %f16, %f1086;
	setp.lt.f32 	%p59, %f1086, %f1215;
	fma.rn.f32 	%f1088, %f1087, 0fBF13CD3A, %f1186;
	fma.rn.f32 	%f1089, %f1087, 0f3F13CD3A, %f1187;
	fma.rn.f32 	%f1090, %f1087, 0f3F13CD3A, %f1188;
	selp.f32 	%f1214, %f1090, %f1214, %p59;
	selp.f32 	%f1213, %f1089, %f1213, %p59;
	selp.f32 	%f1212, %f1088, %f1212, %p59;
	selp.f32 	%f1215, %f1086, %f1215, %p59;

$L__BB0_58:
	sub.f32 	%f1153, %f1187, %f110;
	sub.f32 	%f1149, %f1186, %f110;
	sub.f32 	%f1148, %f1188, %f110;
	mov.f32 	%f1099, 0f00000000;
	mov.u32 	%r1901, 1;
	mov.u32 	%r1904, 2;
	mov.u32 	%r1906, 3;
	// begin inline asm
	call(%r1868,%r1869,%r1870,%r1871,%r1872,%r1873,%r1874,%r1875,%r1876,%r1877,%r1878,%r1879,%r1880,%r1881,%r1882,%r1883,%r1884,%r1885,%r1886,%r1887,%r1888,%r1889,%r1890,%r1891,%r1892,%r1893,%r1894,%r1895,%r1896,%r1897,%r1898,%r1899),_optix_trace_typed_32,(%r1867,%rd2,%f1149,%f1153,%f1148,%f1072,%f1072,%f1072,%f1099,%f1098,%f1099,%r1901,%r1867,%r1867,%r1904,%r1867,%r1906,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867,%r1867);
	// end inline asm
	mov.b32 	%f360, %r1868;
	mov.b32 	%f361, %r1869;
	mov.b32 	%f362, %r1870;
	abs.f32 	%f1101, %f360;
	abs.f32 	%f1102, %f361;
	add.f32 	%f1103, %f1101, %f1102;
	abs.f32 	%f1104, %f362;
	add.f32 	%f1105, %f1103, %f1104;
	setp.eq.f32 	%p60, %f1105, 0f00000000;
	@%p60 bra 	$L__BB0_60;

	mul.f32 	%f1106, %f361, %f361;
	fma.rn.f32 	%f1107, %f360, %f360, %f1106;
	fma.rn.f32 	%f1108, %f362, %f362, %f1107;
	sqrt.rn.f32 	%f1109, %f1108;
	max.f32 	%f1110, %f1109, %f10;
	add.f32 	%f1111, %f16, %f1110;
	setp.lt.f32 	%p61, %f1110, %f1215;
	fma.rn.f32 	%f1112, %f1111, 0f3F13CD3A, %f1186;
	fma.rn.f32 	%f1113, %f1111, 0f3F13CD3A, %f1187;
	fma.rn.f32 	%f1114, %f1111, 0f3F13CD3A, %f1188;
	selp.f32 	%f1214, %f1114, %f1214, %p61;
	selp.f32 	%f1213, %f1113, %f1213, %p61;
	selp.f32 	%f1212, %f1112, %f1212, %p61;
	selp.f32 	%f1215, %f1110, %f1215, %p61;

$L__BB0_60:
	sub.f32 	%f1154, %f1187, %f110;
	sub.f32 	%f1151, %f1188, %f108;
	sub.f32 	%f1150, %f1186, %f110;
	mov.f32 	%f1119, 0f3F13CD3A;
	mov.f32 	%f1120, 0fBF13CD3A;
	mov.u32 	%r2009, 0;
	// begin inline asm
	call(%r1939,%r1940,%r1941,%r1942,%r1943,%r1944,%r1945,%r1946,%r1947,%r1948,%r1949,%r1950,%r1951,%r1952,%r1953,%r1954,%r1955,%r1956,%r1957,%r1958,%r1959,%r1960,%r1961,%r1962,%r1963,%r1964,%r1965,%r1966,%r1967,%r1968,%r1969,%r1970),_optix_trace_typed_32,(%r2009,%rd2,%f1150,%f1154,%f1151,%f1119,%f1119,%f1120,%f1099,%f1122,%f1099,%r1901,%r2009,%r2009,%r1904,%r2009,%r1906,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009,%r2009);
	// end inline asm
	mov.b32 	%f371, %r1939;
	mov.b32 	%f372, %r1940;
	mov.b32 	%f373, %r1941;
	abs.f32 	%f1125, %f371;
	abs.f32 	%f1126, %f372;
	add.f32 	%f1127, %f1125, %f1126;
	abs.f32 	%f1128, %f373;
	add.f32 	%f1129, %f1127, %f1128;
	setp.eq.f32 	%p62, %f1129, 0f00000000;
	@%p62 bra 	$L__BB0_62;

	mul.f32 	%f1130, %f372, %f372;
	fma.rn.f32 	%f1131, %f371, %f371, %f1130;
	fma.rn.f32 	%f1132, %f373, %f373, %f1131;
	sqrt.rn.f32 	%f1133, %f1132;
	max.f32 	%f1134, %f1133, %f10;
	add.f32 	%f1135, %f16, %f1134;
	setp.lt.f32 	%p63, %f1134, %f1215;
	fma.rn.f32 	%f1136, %f1135, 0f3F13CD3A, %f1186;
	fma.rn.f32 	%f1137, %f1135, 0f3F13CD3A, %f1187;
	fma.rn.f32 	%f1138, %f1135, 0fBF13CD3A, %f1188;
	selp.f32 	%f1214, %f1138, %f1214, %p63;
	selp.f32 	%f1213, %f1137, %f1213, %p63;
	selp.f32 	%f1212, %f1136, %f1212, %p63;

$L__BB0_62:
	add.s32 	%r2014, %r2014, 1;
	setp.lt.u32 	%p64, %r2014, 2;
	mov.f32 	%f1186, %f1212;
	mov.f32 	%f1187, %f1213;
	mov.f32 	%f1188, %f1214;
	@%p64 bra 	$L__BB0_18;

	ld.const.u64 	%rd38, [params+224];
	cvta.to.global.u64 	%rd39, %rd38;
	ld.const.u32 	%r2010, [params+216];
	mad.lo.s32 	%r2011, %r2010, %r4, %r3;
	mul.wide.u32 	%rd40, %r2011, 16;
	add.s64 	%rd41, %rd39, %rd40;
	mov.f32 	%f1139, 0f3F800000;
	st.global.v4.f32 	[%rd41], {%f1212, %f1213, %f1214, %f1139};

$L__BB0_65:
	ret;

}

